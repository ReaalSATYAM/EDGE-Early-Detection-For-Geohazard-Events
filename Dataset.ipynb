{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMbgFEnIeCB0x/1iFeFq+E3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SC97yto4FL7X","executionInfo":{"status":"ok","timestamp":1769108541170,"user_tz":-330,"elapsed":77929,"user":{"displayName":"Satyam Naithani","userId":"16072452087119800208"}},"outputId":"316f5eef-8a7e-44d3-a47f-2852831b2037"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["1. Data path and dataset organization module"],"metadata":{"id":"S0ad6j89uwB_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"GXIIb-IIukwR"},"outputs":[],"source":["import os\n","import glob\n","\n","BASE_DIR = \"/content/drive/MyDrive/sentinel_lewsData/shimla\"\n","\n","# Soil types\n","soil_types = [\"clay\", \"sand\", \"silt\", \"bulk\"]\n","soil_files = {soil: [] for soil in soil_types}\n","\n","# Scan soil folder for all depth layers(0-5, 5-15, 15-30, 30-60, 60-100)\n","for soil in soil_types:\n","    pattern = os.path.join(BASE_DIR, f\"soil/shimla_{soil}*.tif\")\n","    files = sorted(glob.glob(pattern))\n","    soil_files[soil] = files\n","\n","# Paths dictionary\n","PATHS = {\n","    \"boundary\": os.path.join(BASE_DIR, \"boundary/shimla_boundary.geojson\"),\n","    \"dem\": os.path.join(BASE_DIR, \"dem/dem.tif\"),\n","    \"lulc\": os.path.join(BASE_DIR, \"lulc/lulc.tif\"),\n","    \"soil\": soil_files,\n","    \"rain_excel\": os.path.join(BASE_DIR, \"rainfall/shimla_rain.xlsx\"),\n","    \"output\": os.path.join(BASE_DIR, \"outputs\")\n","}\n","\n","output_folder = os.path.join(BASE_DIR, \"outputs\")\n","if not os.path.exists(output_folder):\n","    os.mkdir(output_folder)"]},{"cell_type":"markdown","source":["2. Creates a **10 m × 10 m spatial analysis** grid over the Shimla district boundary and prepares it **for cell-wise landslide risk modeling**."],"metadata":{"id":"4vMk8swD5oQA"}},{"cell_type":"code","source":["import geopandas as gpd\n","import numpy as np\n","from shapely.geometry import box\n","\n","# Load boundary\n","boundary = gpd.read_file(PATHS[\"boundary\"])\n","\n","# Reproject to metric CRS (Coordinate Reference System)\n","boundary = boundary.to_crs(epsg=32643)\n","\n","# Grid resolution (meters)\n","GRID_SIZE = 10  # 100m × 100m\n","\n","# Get bounds\n","minx, miny, maxx, maxy = boundary.total_bounds\n","\n","grid_cells = []\n","grid_id = 0\n","\n","x_coords = np.arange(minx, maxx, GRID_SIZE)\n","y_coords = np.arange(miny, maxy, GRID_SIZE)\n","\n","for x in x_coords:\n","    for y in y_coords:\n","        cell = box(x, y, x + GRID_SIZE, y + GRID_SIZE)\n","        if boundary.intersects(cell).any():\n","            grid_cells.append({\n","                \"grid_id\": grid_id,\n","                \"geometry\": cell\n","            })\n","            grid_id += 1\n","\n","grid = gpd.GeoDataFrame(grid_cells, crs=boundary.crs)\n","\n","# Storing lat/lon for output\n","grid_latlon = grid.to_crs(epsg=4326)\n","grid[\"lat\"] = grid_latlon.geometry.centroid.y\n","grid[\"lon\"] = grid_latlon.geometry.centroid.x\n","\n","print(f\"Total grid cells created: {len(grid)}\")\n"],"metadata":{"id":"Hzdl5RW3u-Gf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3. Preparing the DEM so that slope and elevation can be derived correctly"],"metadata":{"id":"gRIWrorh8fH5"}},{"cell_type":"code","source":["import rasterio\n","from rasterio.warp import calculate_default_transform, reproject, Resampling\n","import os\n","\n","src_path = PATHS[\"dem\"]\n","dst_path = src_path.replace(\".tif\", \"_utm43.tif\")\n","\n","with rasterio.open(src_path) as src:\n","    transform, width, height = calculate_default_transform(\n","        src.crs,\n","        \"EPSG:32643\",\n","        src.width,\n","        src.height,\n","        *src.bounds\n","    )\n","\n","    kwargs = src.meta.copy()\n","    kwargs.update({\n","        \"crs\": \"EPSG:32643\",\n","        \"transform\": transform,\n","        \"width\": width,\n","        \"height\": height\n","    })\n","\n","    with rasterio.open(dst_path, \"w\", **kwargs) as dst:\n","        for i in range(1, src.count + 1):\n","            reproject(\n","                source=rasterio.band(src, i),\n","                destination=rasterio.band(dst, i),\n","                src_transform=src.transform,\n","                src_crs=src.crs,\n","                dst_transform=transform,\n","                dst_crs=\"EPSG:32643\",\n","                resampling=Resampling.bilinear\n","            )\n","\n","print(\"Reprojected DEM saved as:\", dst_path)\n","PATHS[\"dem\"] = PATHS[\"dem\"].replace(\".tif\", \"_utm43.tif\")"],"metadata":{"id":"xXdb5pzLxpbf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4. This script derives terrain parameters (elevation and slope) from the reprojected DEM and assigns them to each 100 m × 100 m grid cell using the grid cell centroid."],"metadata":{"id":"MSgn2P9l8xyR"}},{"cell_type":"code","source":["import rasterio\n","import numpy as np\n","\n","with rasterio.open(PATHS[\"dem\"]) as src:\n","    dem = src.read(1).astype(\"float32\")\n","    transform = src.transform\n","    dem_crs = src.crs\n","    res_x = transform.a\n","    res_y = -transform.e\n","\n","# Pad DEM to avoid edge issues\n","z = np.pad(dem, 1, mode=\"edge\")\n","\n","dzdx = (\n","    (z[1:-1, 2:] + 2*z[2:, 2:] + z[2:, 1:-1]) -\n","    (z[1:-1, :-2] + 2*z[:-2, :-2] + z[:-2, 1:-1])\n",") / (8 * res_x)\n","\n","dzdy = (\n","    (z[2:, 1:-1] + 2*z[2:, :-2] + z[1:-1, :-2]) -\n","    (z[:-2, 1:-1] + 2*z[:-2, 2:] + z[1:-1, 2:])\n",") / (8 * res_y)\n","\n","slope_rad = np.arctan(np.sqrt(dzdx**2 + dzdy**2))\n","slope_deg = np.degrees(slope_rad)\n","\n","grid_dem = grid.to_crs(dem_crs)\n","\n","from rasterio.transform import rowcol\n","\n","elevations = []\n","slopes = []\n","\n","# Assign slope and elevation to the centroid\n","for geom in grid_dem.geometry:\n","    x, y = geom.centroid.x, geom.centroid.y\n","    row, col = rowcol(transform, x, y)\n","\n","    if 0 <= row < dem.shape[0] and 0 <= col < dem.shape[1]:\n","        elevations.append(dem[row, col])\n","        slopes.append(slope_deg[row, col])\n","    else:\n","        elevations.append(np.nan)\n","        slopes.append(np.nan)\n","\n","grid[\"elevation\"] = elevations\n","grid[\"slope\"] = slopes\n","\n","# Sanity Check\n","grid[[\"elevation\", \"slope\"]].describe()\n","\n","# Saving progress\n","grid.drop(columns=\"geometry\").to_csv(\n","    os.path.join(PATHS[\"output\"], \"shimla_grid_with_dem.csv\"),\n","    index=False\n",")\n","\n","print(\"DEM + slope added and saved\")\n"],"metadata":{"id":"b9-Nn8MFx4dX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["5. This script extracts soil properties from multi-depth raster datasets, computes a depth-weighted average for each soil parameter, and assigns the resulting values to each 100 m grid cell."],"metadata":{"id":"kLcZlfKfGyKr"}},{"cell_type":"code","source":["def sample_raster_mean(raster_path, grid_gdf):\n","    with rasterio.open(raster_path) as src:\n","        raster_crs = src.crs\n","        grid_proj = grid_gdf.to_crs(raster_crs)\n","\n","        coords = [(geom.x, geom.y) for geom in grid_proj.geometry.centroid]\n","\n","        values = np.array(list(src.sample(coords)), dtype=\"float32\").flatten()\n","\n","        nodata = src.nodata\n","        if nodata is not None:\n","            values[values == nodata] = np.nan\n","\n","        return values\n","\n","soil_depth_weights = {\n","    \"0-5\": 0.05,\n","    \"5-15\": 0.10,\n","    \"15-30\": 0.15,\n","    \"30-60\": 0.30,\n","    \"60-100\": 0.40\n","}\n","\n","for soil_type, files in PATHS[\"soil\"].items():\n","    print(f\"Processing {soil_type}...\")\n","\n","    weighted_sum = np.zeros(len(grid), dtype=\"float32\")\n","\n","    for f in files:\n","        for depth in soil_depth_weights:\n","            if depth in f:\n","                weight = soil_depth_weights[depth]\n","                break\n","\n","        values = sample_raster_mean(f, grid)\n","        weighted_sum += values * weight\n","\n","    grid[soil_type] = weighted_sum\n","\n","# Convert g/kg → %\n","grid[\"clay\"] = grid[\"clay\"] / 10\n","grid[\"sand\"] = grid[\"sand\"] / 10\n","grid[\"silt\"] = grid[\"silt\"] / 10\n","\n","# Sanity check\n","grid[[\"clay\", \"sand\", \"silt\", \"bulk\"]].describe()\n","\n"],"metadata":{"id":"qKwNXsq0yXNQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["6. This script extracts Land Use / Land Cover (LULC) information from a raster map and assigns a LULC class label to each 100 m grid cell based on the grid cell’s centroid location."],"metadata":{"id":"1OCC2X2YLnvb"}},{"cell_type":"code","source":["import rasterio\n","import numpy as np\n","import geopandas as gpd\n","from rasterio.features import geometry_mask\n","from rasterio.sample import sample_gen\n","\n","lulc_path = PATHS[\"lulc\"]\n","\n","with rasterio.open(lulc_path) as src:\n","    lulc = src.read(1)\n","    lulc_transform = src.transform\n","    lulc_crs = src.crs\n","    lulc_nodata = src.nodata\n","\n","print(lulc_crs, lulc_transform)\n","\n","lulc_src = rasterio.open(PATHS[\"lulc\"])\n","\n","def sample_lulc(lon, lat):\n","    \"\"\"\n","    Sample LULC value at given lon, lat\n","    \"\"\"\n","    val = list(\n","        lulc_src.sample([(lon, lat)])\n","    )[0][0]\n","\n","    # Handle nodata\n","    if val == lulc_src.nodata:\n","        return None\n","    return int(val)\n","\n","grid[\"lulc\"] = grid.apply(\n","    lambda row: sample_lulc(row[\"lon\"], row[\"lat\"]),\n","    axis=1\n",")\n","\n","# Features\n","grid[\"lulc\"].value_counts().sort_index()\n"],"metadata":{"id":"665_DSDUzIWU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["7. This script processes rainfall time-series data, computes antecedent rainfall indicators, and assigns them to every 100 m grid cell as triggering factors for landslide prediction."],"metadata":{"id":"bTqcgK4mN4Yx"}},{"cell_type":"code","source":["import pandas as pd\n","rain = pd.read_excel(PATHS[\"rain_excel\"])\n","\n","rain = rain.rename(columns={\n","    \"Data Time\": \"date\",\n","    \"Data Value\": \"rain_mm\"\n","})\n","\n","rain[\"date\"] = pd.to_datetime(rain[\"date\"])\n","\n","# Time Series\n","rain = rain.sort_values(\"date\").reset_index(drop=True)\n","\n","rain = rain[[\"date\", \"rain_mm\"]]\n","\n","# Rolling rainfall\n","rain[\"R_7d\"] = rain[\"rain_mm\"].rolling(7).sum().shift(1)\n","rain[\"R_30d\"] = rain[\"rain_mm\"].rolling(30).sum().shift(1)\n","\n","latest = rain.dropna().iloc[-1]\n","\n","R_7d = latest[\"R_7d\"]\n","R_30d = latest[\"R_30d\"]\n","\n","grid[\"R_7d\"] = R_7d\n","grid[\"R_30d\"] = R_30d\n","\n","out_file = os.path.join(PATHS[\"output\"], \"shimla_model_grid.csv\")\n","\n","grid.drop(columns=\"geometry\").to_csv(\n","    out_file,\n","    index=False\n",")\n","\n","\n"],"metadata":{"id":"SaWyAp4H0KRC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["8. Dataset Cleaning"],"metadata":{"id":"QzDGeej02_Am"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from scipy import ndimage\n","from scipy.stats import mode\n","\n","grid_file = os.path.join(PATHS[\"output\"], \"shimla_model_grid.parquet\")\n","grid = pd.read_parquet(grid_file)\n","\n","# Step 1: Fill elevation & slope NaNs using nearest neighbor\n","for col in [\"elevation\", \"slope\"]:\n","    data = grid[col].values\n","    mask = np.isnan(data)\n","\n","    if mask.any():\n","        indices = np.arange(len(data))\n","        valid_idx = indices[~mask]\n","        valid_values = data[~mask]\n","\n","        # Fill NaNs using nearest valid value\n","        filled_values = np.interp(indices, valid_idx, valid_values)\n","        grid[col] = filled_values.astype(data.dtype)\n","\n","# Step 2: Fill LULC NaNs with mode of neighboring cells\n","if grid[\"lulc\"].isna().any():\n","    grid[\"lulc\"] = grid[\"lulc\"].fillna(method=\"ffill\").fillna(method=\"bfill\")\n","\n","# Step 3: Save the cleaned grid\n","clean_file = os.path.join(PATHS[\"output\"], \"shimla_model_grid_clean.csv\")\n","grid.to_csv(clean_file)\n","\n","# Optional: check remaining NaNs\n","print(grid.isna().sum())\n"],"metadata":{"id":"Ye2tDPWy2h9t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["9. This script extracts monthly satellite rainfall (IMERG) values for every 100 m grid cell in Shimla and builds a time-series table."],"metadata":{"id":"_GCuQCYeectt"}},{"cell_type":"code","source":["import os\n","import rasterio\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","\n","PATHS[\"rainfall_folder\"] = os.path.join(BASE_DIR, \"rainfall/imerg_monthly\")\n","grid_file = os.path.join(PATHS[\"output\"], \"shimla_model_grid_clean.csv\")\n","grid = pd.read_csv(grid_file)\n","\n","coords = list(zip(grid[\"lon\"].values, grid[\"lat\"].values))\n","grid_ids = grid[\"grid_id\"].values\n","\n","rain_output = os.path.join(PATHS[\"output\"], \"shimla_grid_imerg_monthly.csv\")\n","\n","lons = grid[\"lon\"].values\n","lats = grid[\"lat\"].values\n","grid_ids = grid[\"grid_id\"].values\n","\n","monthly_rain = pd.DataFrame(index=grid_ids)\n","\n","imerg_folder = os.path.join(BASE_DIR, \"rainfall/imerg_monthly\")\n","imerg_files = sorted([f for f in os.listdir(imerg_folder) if f.endswith(\".tif\")])\n","\n","def parse_date(filename):\n","    base = os.path.basename(filename).replace(\".tif\", \"\")\n","    parts = base.split(\"_\")\n","    year = int(parts[2])\n","    month = int(parts[3])\n","    return pd.Timestamp(year=year, month=month, day=1)\n","\n","dates = [parse_date(f) for f in imerg_files]\n","\n","for f, date in tqdm(zip(imerg_files, dates), total=len(imerg_files), desc=\"Processing Imerg\"):\n","    path = os.path.join(imerg_folder, f)\n","\n","    with rasterio.open(path) as src:\n","        data = src.read(1)\n","        transform = src.transform\n","        col_inds = ((lons - transform.c) / transform.a).astype(int)\n","        row_inds = ((lats - transform.f) / transform.e).astype(int)\n","\n","        row_inds = np.clip(row_inds, 0, src.height - 1)\n","        col_inds = np.clip(col_inds, 0, src.width - 1)\n","\n","        vals = data[row_inds, col_inds]\n","        vals = np.nan_to_num(vals, 0.0)\n","\n","        monthly_rain[date] = vals\n","\n","monthly_rain.to_csv(rain_output)\n","print(\"Saved monthly rainfall for all grid cells to:\", rain_output)\n"],"metadata":{"id":"hst3Gz6Z3IPH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["10. Creating final dataset"],"metadata":{"id":"gIT4xnsAembx"}},{"cell_type":"code","source":["import pandas as pd\n","import os\n","\n","# Paths\n","main_grid_file = os.path.join(PATHS[\"output\"], \"shimla_model_grid_clean.parquet\")\n","rain_file = os.path.join(PATHS[\"output\"], \"shimla_grid_imerg_monthly.csv\")\n","final_output_csv = os.path.join(PATHS[\"output\"], \"shimla_final_grid.csv\")\n","\n","# Load files\n","grid = pd.read_parquet(main_grid_file)\n","rain = pd.read_csv(rain_file, index_col=0)\n","\n","# Merge on grid_id (index)\n","grid = grid.set_index(\"grid_id\")\n","final_grid = grid.join(rain, how=\"left\")\n","\n","# Optional: fill any NaNs in rainfall with 0\n","final_grid[rain.columns] = final_grid[rain.columns].fillna(0)\n","\n","# Save final dataset as CSV\n","final_grid.to_csv(final_output_csv)\n","print(\"Final grid saved to:\", final_output_csv)\n"],"metadata":{"id":"6wSWyBL-3h8Z"},"execution_count":null,"outputs":[]}]}
